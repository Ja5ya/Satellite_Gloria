{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing zip files\n",
    "folder_path = 'Satellite data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the DataFrames\n",
    "dataframes = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20231117_120secMother_AllCountries_002_TQ-Results_1990_059_Markup001(full).csv into DataFrame.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the folder containing zip files\n",
    "folder_path = 'Satellite data'\n",
    "\n",
    "# Specific zip file and TQ file to read\n",
    "zip_filename = 'GLORIA_SatelliteAccounts_059_1990.zip'\n",
    "specific_tq_file_name = '20231117_120secMother_AllCountries_002_TQ-Results_1990_059_Markup001(full).csv'\n",
    "\n",
    "# Path to the specific zip file\n",
    "zip_path = os.path.join(folder_path, zip_filename)\n",
    "\n",
    "# Dictionary to store the DataFrame\n",
    "dataframes = {}\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    # Check if the specific TQ file is in the zip\n",
    "    if specific_tq_file_name in zip_ref.namelist():\n",
    "        # Read the CSV file into a DataFrame\n",
    "        with zip_ref.open(specific_tq_file_name) as file:\n",
    "            df = pd.read_csv(file)\n",
    "            # Store the DataFrame in the dictionary with the filename as the key\n",
    "            dataframes[specific_tq_file_name] = df\n",
    "            print(f\"Loaded {specific_tq_file_name} into DataFrame.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5981 entries, 0 to 5980\n",
      "Columns: 39360 entries, 0 to 0.39257\n",
      "dtypes: float64(19556), int64(19804)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of the DataFrame:\n",
      "                 0          0.1            0.2           0.3       209553  \\\n",
      "count  5981.000000  5981.000000    5981.000000   5981.000000  5981.000000   \n",
      "mean      1.922038     4.425283      40.399570      6.470695     2.131069   \n",
      "std      69.419922   167.713523    2620.481021    218.734446    69.213205   \n",
      "min       0.000000     0.000000       0.000000      0.000000     0.000000   \n",
      "25%       0.000000     0.000000       0.000000      0.000000     0.000000   \n",
      "50%       0.000000     0.000000       0.000000      0.000000     0.000000   \n",
      "75%       0.000000     0.000000       0.000000      0.000000     0.000000   \n",
      "max    3838.633204  9453.000000  201170.880000  10822.609530  3428.109011   \n",
      "\n",
      "                0.4           0.5          0.6           0.7          0.8  \\\n",
      "count   5981.000000  5.981000e+03  5981.000000   5981.000000  5981.000000   \n",
      "mean      50.606025  5.250928e+02     0.678763      5.415432     0.333900   \n",
      "std     1184.766129  4.056604e+04    26.944835    203.409711    16.553890   \n",
      "min        0.000000  0.000000e+00     0.000000      0.000000     0.000000   \n",
      "25%        0.000000  0.000000e+00     0.000000      0.000000     0.000000   \n",
      "50%        0.000000  0.000000e+00     0.000000      0.000000     0.000000   \n",
      "75%        0.000000  0.000000e+00     0.000000      0.000000     0.000000   \n",
      "max    59459.835298  3.137253e+06  1621.815188  11981.838461  1126.931571   \n",
      "\n",
      "       ...  0.39248  0.39249  0.39250  0.39251  0.39252  0.39253  0.39254  \\\n",
      "count  ...   5981.0   5981.0   5981.0   5981.0   5981.0   5981.0   5981.0   \n",
      "mean   ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "std    ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "min    ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "25%    ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "50%    ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "75%    ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "max    ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "       0.39255  0.39256  0.39257  \n",
      "count   5981.0   5981.0   5981.0  \n",
      "mean       0.0      0.0      0.0  \n",
      "std        0.0      0.0      0.0  \n",
      "min        0.0      0.0      0.0  \n",
      "25%        0.0      0.0      0.0  \n",
      "50%        0.0      0.0      0.0  \n",
      "75%        0.0      0.0      0.0  \n",
      "max        0.0      0.0      0.0  \n",
      "\n",
      "[8 rows x 39360 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print a concise summary of the DataFrame\n",
    "print(\"\\nSummary of the DataFrame:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types of Each Column:\n",
      "0          float64\n",
      "0.1        float64\n",
      "0.2        float64\n",
      "0.3        float64\n",
      "209553     float64\n",
      "            ...   \n",
      "0.39253      int64\n",
      "0.39254      int64\n",
      "0.39255      int64\n",
      "0.39256      int64\n",
      "0.39257      int64\n",
      "Length: 39360, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print data types of each column\n",
    "print(\"\\nData Types of Each Column:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No Missing Values Found.\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Print a message indicating if there are missing values\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\nMissing Values Found:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"\\nNo Missing Values Found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Few Rows:\n",
      "     0  0.1        0.2  0.3  209553  0.4  0.5  0.6  0.7  0.8  ...  0.39248  \\\n",
      "0  0.0  0.0  201170.88  0.0     0.0  0.0  0.0  0.0  0.0  0.0  ...        0   \n",
      "1  0.0  0.0       0.00  0.0     0.0  0.0  0.0  0.0  0.0  0.0  ...        0   \n",
      "2  0.0  0.0       0.00  0.0     0.0  0.0  0.0  0.0  0.0  0.0  ...        0   \n",
      "3  0.0  0.0       0.00  0.0     0.0  0.0  0.0  0.0  0.0  0.0  ...        0   \n",
      "4  0.0  0.0       0.00  0.0     0.0  0.0  0.0  0.0  0.0  0.0  ...        0   \n",
      "\n",
      "   0.39249  0.39250  0.39251  0.39252  0.39253  0.39254  0.39255  0.39256  \\\n",
      "0        0        0        0        0        0        0        0        0   \n",
      "1        0        0        0        0        0        0        0        0   \n",
      "2        0        0        0        0        0        0        0        0   \n",
      "3        0        0        0        0        0        0        0        0   \n",
      "4        0        0        0        0        0        0        0        0   \n",
      "\n",
      "   0.39257  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "\n",
      "[5 rows x 39360 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows of the DataFrame\n",
    "print(\"\\nFirst Few Rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file Metadata\n",
    "file_path = 'GLORIA_ReadMe_059.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Sequential region-sector labels')\n",
    "\n",
    "# Extract the column of interest\n",
    "labels = df['Sequential_regionSector_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Sequential_regionSector_labels           Country  \\\n",
      "0      Rest of Americas (XAM) Growing wheat industry  Rest of Americas   \n",
      "1      Rest of Americas (XAM) Growing maize industry  Rest of Americas   \n",
      "2  Rest of Americas (XAM) Growing cereals n.e.c i...  Rest of Americas   \n",
      "3  Rest of Americas (XAM) Growing leguminous crop...  Rest of Americas   \n",
      "4       Rest of Americas (XAM) Growing rice industry  Rest of Americas   \n",
      "\n",
      "  Country_Code                                         Industry  \n",
      "0          XAM                           Growing wheat industry  \n",
      "1          XAM                           Growing maize industry  \n",
      "2          XAM                   Growing cereals n.e.c industry  \n",
      "3          XAM  Growing leguminous crops and oil seeds industry  \n",
      "4          XAM                            Growing rice industry  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to the Excel file\n",
    "file_path = 'GLORIA_ReadMe_059.xlsx'\n",
    "\n",
    "# Load the specific sheet and column\n",
    "df = pd.read_excel(file_path, sheet_name='Sequential region-sector labels', usecols=['Sequential_regionSector_labels'])\n",
    "\n",
    "# Function to parse the 'Sequential_regionSector_labels' column\n",
    "def parse_labels(label):\n",
    "    # Find the last set of parentheses for the country code\n",
    "    match = re.search(r'\\((\\w{3})\\)', label)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the country code\n",
    "        country_code = match.group(1).strip()\n",
    "        \n",
    "        # Remove the country code part and trim the remaining string\n",
    "        label_without_code = label[:match.start()].strip()\n",
    "        industry_part = label[match.end():].strip()\n",
    "        \n",
    "        # Extract the country as everything before the last set of parentheses\n",
    "        last_open_bracket_index = label_without_code.rfind('(')\n",
    "        if last_open_bracket_index != -1:\n",
    "            country = label_without_code[:last_open_bracket_index].strip()\n",
    "        else:\n",
    "            country = label_without_code.strip()\n",
    "        \n",
    "        # The remaining part after the country code is the industry\n",
    "        industry = industry_part.strip()\n",
    "        \n",
    "        return pd.Series([country, country_code, industry], index=['Country', 'Country_Code', 'Industry'])\n",
    "    else:\n",
    "        # Handle cases where no country code is found\n",
    "        return pd.Series([label, None, None], index=['Country', 'Country_Code', 'Industry'])\n",
    "\n",
    "# Apply the parsing function to the DataFrame\n",
    "df[['Country', 'Country_Code', 'Industry']] = df['Sequential_regionSector_labels'].apply(parse_labels)\n",
    "\n",
    "# Drop the original column\n",
    "# df.drop(columns=['Sequential_regionSector_labels'], inplace=True)\n",
    "\n",
    "# Print the first few rows of the resulting DataFrame\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of distinct 'Country' values: 164\n",
      "\n",
      "Total number of distinct 'Country_Code' values: 164\n",
      "Total number of distinct 'Industry' values: 240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the total number of distinct 'Country' values\n",
    "num_distinct_countries = df['Country'].nunique()\n",
    "print(f\"\\nTotal number of distinct 'Country' values: {num_distinct_countries}\")\n",
    "\n",
    "# Print the total number of distinct 'Country' values\n",
    "num_distinct_countries = df['Country_Code'].nunique()\n",
    "print(f\"\\nTotal number of distinct 'Country_Code' values: {num_distinct_countries}\")\n",
    "\n",
    "# Print the total number of distinct 'Industry' values\n",
    "num_distinct_industries = df['Industry'].nunique()\n",
    "print(f\"Total number of distinct 'Industry' values: {num_distinct_industries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39360, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull all files for row 5944, 240 industries * 164 countries + 2(year, filename) = 39362 columns\n",
    "*Accompanying satellite accounts (extensions)*, covering GHG emissions, materials, \n",
    "energy, air pollution, land use, water use, biodiversity, skills and employment. \n",
    "Files: \n",
    "YYYYMMDD_120secMother_AllCountries_002_TQ-Results_YYYY_059_ \n",
    "Markup00V(full).csv and YYYYMMDD_120secMother_AllCountries_002_YQ-Results_ \n",
    "YYYY_059_Markup00V(full).csv, with TQ being the intermediate satellite block \n",
    "(matching intermediate transactions T), and YQ the final satellite block (matching final \n",
    "demand Y).\n",
    "\n",
    "20231117_120secMother_AllCountries_002_TQ-Results_1990_059_Markup001(full)\n",
    "\n",
    "\n",
    "GLORIA Multi-region input-output (MRIO) database\n",
    "Files: \n",
    "YYYYMMDD_120secMother_AllCountries_002_VAR-Results_YYYY_059_ \n",
    "Markup00M(full).csv, with VAR = {T,Y,V} being supply-use transactions (T), final \n",
    "demand (Y) and value added (v), and M = 1,…,5 being valuations.  \n",
    "Note I: Transaction and satellite tables are sized 164 ´ (120´2) = 39,360 region-sector pairs, because of \n",
    "the supply-use format. For all labels and the MR-SUT structure, please consult the documentation file \n",
    "GLORIA_ReadMe.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (39, 39362)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to the folder containing zip files\n",
    "folder_path = 'Satellite data'\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "def extract_year(filename):\n",
    "    # Regular expression pattern to match the year in the filename\n",
    "    pattern = r'_TQ-Results_(\\d{4})_'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "# Iterate through each zip file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.zip'):\n",
    "        zip_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # Iterate through each file in the zip\n",
    "            for file_info in zip_ref.infolist():\n",
    "                if 'TQ-Results' in file_info.filename:\n",
    "                    # Extract the year from the filename\n",
    "                    year = extract_year(file_info.filename)\n",
    "                    \n",
    "                    with zip_ref.open(file_info.filename) as file:\n",
    "                        # Read the CSV file into a DataFrame, extracting only row 5944\n",
    "                        df = pd.read_csv(file, skiprows=range(5943), nrows=1, header=None)\n",
    "                        df.index = [5943]  # Set index to the row number\n",
    "                        df['Year'] = year  # Add the year column\n",
    "                        df['Source_Filename'] = file_info.filename  # Add the filename column\n",
    "                        \n",
    "                        # Append the DataFrame to the list\n",
    "                        dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dataframes)\n",
    "\n",
    "# Reset index for the final DataFrame (optional)\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Combined DataFrame shape: {final_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optionally save the final DataFrame to a file\n",
    "final_df.to_csv('combined_row_5944.csv', index=False)\n",
    "\n",
    "print(f\"Combined DataFrame shape: {final_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the combined DataFrame (replace with your actual loading code)\n",
    "combined_df = pd.read_csv('combined_row_5944.csv')  # Or use pd.HDFStore if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 887. MiB for an array with shape (19437, 5981) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTQ-Results\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file_info\u001b[38;5;241m.\u001b[39mfilename:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zip_ref\u001b[38;5;241m.\u001b[39mopen(file_info\u001b[38;5;241m.\u001b[39mfilename) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 13\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# Store the DataFrame in the dictionary with a meaningful key\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         dataframes[file_info\u001b[38;5;241m.\u001b[39mfilename] \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2144\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32md:\\Morescope\\Satellitev2\\sat-env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2301\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2298\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2300\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2301\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2302\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2304\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 887. MiB for an array with shape (19437, 5981) and data type float64"
     ]
    }
   ],
   "source": [
    "# Iterate through each zip file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.zip'):\n",
    "        zip_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # Iterate through each file in the zip\n",
    "            for file_info in zip_ref.infolist():\n",
    "                # Check if the file is a TQ file\n",
    "                if 'TQ-Results' in file_info.filename:\n",
    "                    # Read the CSV file into a DataFrame\n",
    "                    with zip_ref.open(file_info.filename) as file:\n",
    "                        df = pd.read_csv(file)\n",
    "                        # Store the DataFrame in the dictionary with a meaningful key\n",
    "                        dataframes[file_info.filename] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
